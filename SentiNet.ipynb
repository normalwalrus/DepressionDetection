{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from IPython.display import clear_output\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(files):\n",
    "\n",
    "    data_path = os.getcwd()+'/Data/'\n",
    "    combined_df = pd.DataFrame(columns=['text', 'label'])\n",
    "    df_columns = ['text', 'label']\n",
    "    \n",
    "    for x in files:\n",
    "\n",
    "        df = pd.read_csv(data_path+x)\n",
    "        df = df[df.columns[:2]]\n",
    "        df.columns = df_columns\n",
    "        df['text'] = df['text'].astype(str)\n",
    "\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60488</th>\n",
       "      <td>posting everyday people stop caring  religion ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60489</th>\n",
       "      <td>okay definetly need hear guys opinion ive pret...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60490</th>\n",
       "      <td>cant get dog think ill kill myselfthe last thi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60491</th>\n",
       "      <td>whats point princess bridei really think like ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60492</th>\n",
       "      <td>got nudes person might might know snapchat do ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60493 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                             oh my gosh    1.0\n",
       "1      trouble sleeping, confused mind, restless hear...    1.0\n",
       "2      All wrong, back off dear, forward doubt. Stay ...    1.0\n",
       "3      I've shifted my focus to something else but I'...    1.0\n",
       "4      I'm restless and restless, it's been a month n...    1.0\n",
       "...                                                  ...    ...\n",
       "60488  posting everyday people stop caring  religion ...    0.0\n",
       "60489  okay definetly need hear guys opinion ive pret...    0.0\n",
       "60490  cant get dog think ill kill myselfthe last thi...    1.0\n",
       "60491  whats point princess bridei really think like ...    1.0\n",
       "60492  got nudes person might might know snapchat do ...    0.0\n",
       "\n",
       "[60493 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = ['dataset1.csv', 'dataset2.csv', 'dataset3.csv', 'dataset4.csv', 'dataset5.csv']\n",
    "\n",
    "data_df = get_data(files)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    38545\n",
       "1.0    21943\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_out_dataframe(df):\n",
    "\n",
    "    counts = df['label'].value_counts()\n",
    "\n",
    "    if counts[0] > counts[1]:\n",
    "        desired_count = counts[1]\n",
    "        label = 0\n",
    "        non_label = 1\n",
    "    else:\n",
    "        desired_count = counts[0]\n",
    "        label = 1\n",
    "        non_label = 0\n",
    "\n",
    "    df_balanced = pd.concat([df[df['label'] == label].sample(desired_count), df[df['label'] == non_label]], ignore_index=True)\n",
    "    \n",
    "    return df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    21943\n",
      "1.0    21943\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balanced_df = even_out_dataframe(data_df)\n",
    "print(balanced_df['label'].value_counts())\n",
    "\n",
    "data_df = balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (35108,)\n",
      "shape of test data is (8778,)\n"
     ]
    }
   ],
   "source": [
    "X, y = data_df['text'].values, data_df['label'].values\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size= test_size)\n",
    "\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def Lemmatization(data,name):\n",
    "    def getting2(sen):\n",
    "        \n",
    "        example = sen\n",
    "        output_sentence =[]\n",
    "        word_tokens2 = word_tokenize(example)\n",
    "        lemmatized_output = [lemmatizer.lemmatize(w) for w in word_tokens2]\n",
    "        \n",
    "        # Remove characters which have length less than 2  \n",
    "        without_single_chr = [word for word in lemmatized_output if len(word) > 2]\n",
    "        # Remove numbers\n",
    "        cleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]\n",
    "        \n",
    "        return cleaned_data_title\n",
    "    # Using \"getting2(sen)\" function to append edited sentence to data\n",
    "    x=[]\n",
    "    for i in data[name].values:\n",
    "        x.append(getting2(i))\n",
    "    data[name]=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mUtils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tockenize, padding_, preprocess_string\n\u001b[0;32m      3\u001b[0m DICT_LENGTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[0;32m      4\u001b[0m MAX_STR_LENGTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Utils'"
     ]
    }
   ],
   "source": [
    "from Utils.common_functions import tockenize, padding_, preprocess_string\n",
    "\n",
    "DICT_LENGTH = 100000\n",
    "MAX_STR_LENGTH = 35\n",
    "\n",
    "x_train,x_test,vocab = tockenize(x_train,x_test, DICT_LENGTH)\n",
    "print(f'Length of vocabulary is {len(vocab)}')\n",
    "\n",
    "x_train_pad = padding_(x_train,MAX_STR_LENGTH)\n",
    "x_test_pad = padding_(x_test,MAX_STR_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
