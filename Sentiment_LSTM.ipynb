{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(files):\n",
    "\n",
    "    data_path = os.getcwd()+'/Data/'\n",
    "    combined_df = pd.DataFrame(columns=['text', 'label'])\n",
    "    df_columns = ['text', 'label']\n",
    "    \n",
    "    for x in files:\n",
    "\n",
    "        df = pd.read_csv(data_path+x)\n",
    "        df = df[df.columns[:2]]\n",
    "        df.columns = df_columns\n",
    "        df['text'] = df['text'].astype(str)\n",
    "\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ming Xuan\\AppData\\Local\\Temp\\ipykernel_16548\\622898227.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>\"Nothing beats the feeling of achieving someth...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32512</th>\n",
       "      <td>Too much homework Feeling Stressed!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32513</th>\n",
       "      <td>overworked in school,,  causes me  headache</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32514</th>\n",
       "      <td>How come my friends immediately get to know st...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32515</th>\n",
       "      <td>toady I wake at 5am</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32516 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                             oh my gosh    1.0\n",
       "1      trouble sleeping, confused mind, restless hear...    1.0\n",
       "2      All wrong, back off dear, forward doubt. Stay ...    1.0\n",
       "3      I've shifted my focus to something else but I'...    1.0\n",
       "4      I'm restless and restless, it's been a month n...    1.0\n",
       "...                                                  ...    ...\n",
       "32511  \"Nothing beats the feeling of achieving someth...    0.0\n",
       "32512                Too much homework Feeling Stressed!    1.0\n",
       "32513        overworked in school,,  causes me  headache    1.0\n",
       "32514  How come my friends immediately get to know st...    0.0\n",
       "32515                                toady I wake at 5am    0.0\n",
       "\n",
       "[32516 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = ['dataset1.csv', 'dataset2.csv', 'dataset3.csv', 'dataset4.csv']#, 'dataset5.csv']\n",
    "\n",
    "data_df = get_data(files)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    24406\n",
       "1.0     8105\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_out_dataframe(df):\n",
    "\n",
    "    counts = df['label'].value_counts()\n",
    "\n",
    "    if counts[0] > counts[1]:\n",
    "        desired_count = counts[1]\n",
    "        label = 0\n",
    "        non_label = 1\n",
    "    else:\n",
    "        desired_count = counts[0]\n",
    "        label = 1\n",
    "        non_label = 0\n",
    "\n",
    "    df_balanced = pd.concat([df[df['label'] == label].sample(desired_count), df[df['label'] == non_label]], ignore_index=True)\n",
    "    \n",
    "    return df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    8105\n",
      "1.0    8105\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balanced_df = even_out_dataframe(data_df)\n",
    "print(balanced_df['label'].value_counts())\n",
    "\n",
    "data_df = balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (12968,)\n",
      "shape of test data is (3242,)\n"
     ]
    }
   ],
   "source": [
    "X, y = data_df['text'].values, data_df['label'].values\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size= test_size)\n",
    "\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12968\n",
      "Length of vocabulary is 26333\n"
     ]
    }
   ],
   "source": [
    "from utils.common_functions import tockenize, padding_, preprocess_string\n",
    "\n",
    "DICT_LENGTH = 100000\n",
    "MAX_STR_LENGTH = 64\n",
    "\n",
    "x_train,x_test,vocab = tockenize(x_train,x_test, DICT_LENGTH)\n",
    "print(f'Length of vocabulary is {len(vocab)}')\n",
    "\n",
    "x_train_pad = padding_(x_train,MAX_STR_LENGTH)\n",
    "x_test_pad = padding_(x_test,MAX_STR_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "       10659])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 128\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([64])\n",
      "Sample input: \n",
      " tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0, 10659], dtype=torch.int32)\n",
      "Sample input: \n",
      " tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter._dataset[0]\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    # Takes in 2 tensors\n",
    "\n",
    "    preds, labels = preds.cpu().detach().numpy(), labels.cpu().detach().numpy()\n",
    "\n",
    "    f1 = f1_score(labels, preds, average = 'weighted')\n",
    "    p_score = precision_score(labels, preds)\n",
    "    r_score = recall_score(labels, preds)\n",
    "    return f1, p_score, r_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_loader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    size = len(train_loader.dataset)\n",
    "    num_batches = len(train_loader)\n",
    "\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for word_embed, labels in train_loader:\n",
    "        # Transfering images and labels to GPU if available\n",
    "        word_embed, labels = word_embed.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass \n",
    "        outputs = model(word_embed)\n",
    "        outputs = outputs.type(torch.float64)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        \n",
    "        train_correct += (predicted == labels).type(torch.float).sum().item()\n",
    "\n",
    "    f1, p_score, r_score = f1_score_func(predicted, labels)\n",
    "    train_loss /= num_batches\n",
    "    train_correct /=size\n",
    "    \n",
    "    return train_loss, train_correct, f1, p_score, r_score\n",
    "\n",
    "def test_loop(test_loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "\n",
    "    size = len(test_loader.dataset)\n",
    "    num_batches = len(test_loader)\n",
    "    test_loss, test_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for word_embed, labels in test_loader:\n",
    "\n",
    "            word_embed, labels = word_embed.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(word_embed)\n",
    "            outputs = outputs.type(torch.float64)\n",
    "\n",
    "            test_loss += loss_fn(outputs, labels).item()\n",
    "\n",
    "            predicted = torch.round(outputs)\n",
    "            test_correct += (predicted == labels).type(torch.float).sum().item()\n",
    "\n",
    "    f1, p_score, r_score = f1_score_func(predicted, labels)\n",
    "    test_loss /= num_batches\n",
    "    test_correct /= size\n",
    "    \n",
    "    return test_loss, test_correct, f1, p_score, r_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(26334, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc_extra): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from utils.models import SentimentRNN\n",
    "from utils.early_stopper import EarlyStopper\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
    "embedding_dim = 64\n",
    "hidden_dim = 256\n",
    "patience = 3\n",
    "\n",
    "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim)\n",
    "early_stopper = EarlyStopper(patience=patience, min_delta=0)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ming Xuan\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc epoch 0 : Acc 0.8242597162245527 , F1 0.89923273657289 , Precision 0.9375 , Recall 0.8333333333333334 \n",
      "Test Acc epoch 0 : Acc 0.8852560148056755 , F1 0.9286929746373874 , Precision 1.0 , Recall 0.8695652173913043\n",
      "Train Acc epoch 1 : Acc 0.9110888340530536 , F1 0.846875 , Precision 0.9285714285714286 , Recall 0.7222222222222222 \n",
      "Test Acc epoch 1 : Acc 0.919185687847008 , F1 0.8095238095238095 , Precision 0.7391304347826086 , Recall 0.8947368421052632\n",
      "Train Acc epoch 2 : Acc 0.9431677976557681 , F1 0.95 , Precision 0.9523809523809523 , Recall 0.9523809523809523 \n",
      "Test Acc epoch 2 : Acc 0.9469463294262801 , F1 0.9762039813089161 , Precision 1.0 , Recall 0.9545454545454546\n",
      "Train Acc epoch 3 : Acc 0.9558914250462678 , F1 0.9751481237656353 , Precision 1.0 , Recall 0.96 \n",
      "Test Acc epoch 3 : Acc 0.9524984577421345 , F1 0.9524891774891776 , Precision 1.0 , Recall 0.9130434782608695\n",
      "Train Acc epoch 4 : Acc 0.9666872301048736 , F1 1.0 , Precision 1.0 , Recall 1.0 \n",
      "Test Acc epoch 4 : Acc 0.9518815545959285 , F1 0.9522727272727274 , Precision 1.0 , Recall 0.9047619047619048\n",
      "Train Acc epoch 5 : Acc 0.975400987045034 , F1 0.9749528598365806 , Precision 1.0 , Recall 0.9473684210526315 \n",
      "Test Acc epoch 5 : Acc 0.9552745219000617 , F1 0.9758680378780166 , Precision 1.0 , Recall 0.9166666666666666\n",
      "Train Acc epoch 6 : Acc 0.9824182603331277 , F1 0.95 , Precision 0.9047619047619048 , Recall 1.0 \n",
      "Test Acc epoch 6 : Acc 0.9472547809993831 , F1 0.9762039813089161 , Precision 0.9523809523809523 , Recall 1.0\n",
      "Done! Early stopped at 7\n"
     ]
    }
   ],
   "source": [
    "#from Utils.common_functions import train_loop, test_loop\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 50\n",
    "# train for some number of epochs\n",
    "tr_acc, te_acc = [], []\n",
    "tr_loss, te_loss = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_correct, train_f1, train_p_score, train_r_score = train_loop(train_loader, model, loss_fn, optimizer, device)\n",
    "    test_loss, test_correct, test_f1, test_p_score, test_r_score = test_loop(test_loader, model, loss_fn, device)\n",
    "\n",
    "    print('Train Acc epoch {} : Acc {} , F1 {} , Precision {} , Recall {} '.format(epoch, train_correct, train_f1, train_p_score, train_r_score))\n",
    "    print('Test Acc epoch {} : Acc {} , F1 {} , Precision {} , Recall {}'.format(epoch, test_correct, test_f1, test_p_score, test_r_score))\n",
    "\n",
    "    tr_acc.append(train_correct)\n",
    "    te_acc.append(test_correct)\n",
    "\n",
    "    tr_loss.append(train_loss)\n",
    "    te_loss.append(test_loss)\n",
    "\n",
    "    if early_stopper.early_stop(test_loss):\n",
    "        print(\"Done! Early stopped at {}\".format(epoch+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9978429079055786\n",
      "0.0003846545878332108\n",
      "0.9813715815544128\n",
      "0.027734743431210518\n",
      "0.9998902082443237\n"
     ]
    }
   ],
   "source": [
    "A = 'All I feel is anxiety'\n",
    "B = 'naruto is a great anime'\n",
    "C = 'I dont feel anything anymore'\n",
    "D = 'Lets have a picnic today!'\n",
    "E = 'I am wondering why there is so much talk about depression these days'\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def predict_text(text):\n",
    "    word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \n",
    "                        if preprocess_string(word) in vocab.keys()])\n",
    "    word_seq = np.expand_dims(word_seq,axis=0)\n",
    "    pad =  torch.from_numpy(padding_(word_seq,MAX_STR_LENGTH))\n",
    "    inputs = pad.to(device)\n",
    "    output = model(inputs)\n",
    "    return(output.item())\n",
    "\n",
    "print(predict_text(A))\n",
    "print(predict_text(B))\n",
    "print(predict_text(C))\n",
    "print(predict_text(D))\n",
    "print(predict_text(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
