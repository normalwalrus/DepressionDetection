{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(files):\n",
    "\n",
    "    data_path = os.getcwd()+'/Data/'\n",
    "    combined_df = pd.DataFrame(columns=['text', 'label'])\n",
    "    df_columns = ['text', 'label']\n",
    "    \n",
    "    for x in files:\n",
    "\n",
    "        df = pd.read_csv(data_path+x)\n",
    "        df = df[df.columns[:2]]\n",
    "        df.columns = df_columns\n",
    "        df['text'] = df['text'].astype(str)\n",
    "\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ming Xuan\\AppData\\Local\\Temp\\ipykernel_14012\\622898227.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60488</th>\n",
       "      <td>posting everyday people stop caring  religion ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60489</th>\n",
       "      <td>okay definetly need hear guys opinion ive pret...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60490</th>\n",
       "      <td>cant get dog think ill kill myselfthe last thi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60491</th>\n",
       "      <td>whats point princess bridei really think like ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60492</th>\n",
       "      <td>got nudes person might might know snapchat do ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60493 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                             oh my gosh    1.0\n",
       "1      trouble sleeping, confused mind, restless hear...    1.0\n",
       "2      All wrong, back off dear, forward doubt. Stay ...    1.0\n",
       "3      I've shifted my focus to something else but I'...    1.0\n",
       "4      I'm restless and restless, it's been a month n...    1.0\n",
       "...                                                  ...    ...\n",
       "60488  posting everyday people stop caring  religion ...    0.0\n",
       "60489  okay definetly need hear guys opinion ive pret...    0.0\n",
       "60490  cant get dog think ill kill myselfthe last thi...    1.0\n",
       "60491  whats point princess bridei really think like ...    1.0\n",
       "60492  got nudes person might might know snapchat do ...    0.0\n",
       "\n",
       "[60493 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = ['dataset1.csv', 'dataset2.csv', 'dataset3.csv', 'dataset4.csv', 'dataset5.csv']\n",
    "\n",
    "data_df = get_data(files)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    38545\n",
       "1.0    21943\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_out_dataframe(df):\n",
    "\n",
    "    counts = df['label'].value_counts()\n",
    "\n",
    "    if counts[0] > counts[1]:\n",
    "        desired_count = counts[1]\n",
    "        label = 0\n",
    "        non_label = 1\n",
    "    else:\n",
    "        desired_count = counts[0]\n",
    "        label = 1\n",
    "        non_label = 0\n",
    "\n",
    "    df_balanced = pd.concat([df[df['label'] == label].sample(desired_count), df[df['label'] == non_label]], ignore_index=True)\n",
    "    \n",
    "    return df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    21943\n",
      "1.0    21943\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balanced_df = even_out_dataframe(data_df)\n",
    "print(balanced_df['label'].value_counts())\n",
    "\n",
    "data_df = balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (35108,)\n",
      "shape of test data is (8778,)\n"
     ]
    }
   ],
   "source": [
    "X, y = data_df['text'].values, data_df['label'].values\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size= test_size)\n",
    "\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35108\n",
      "Length of vocabulary is 69939\n"
     ]
    }
   ],
   "source": [
    "from utils.common_functions import tockenize, padding_, preprocess_string\n",
    "\n",
    "DICT_LENGTH = 100000\n",
    "MAX_STR_LENGTH = 60\n",
    "\n",
    "x_train,x_test,vocab = tockenize(x_train,x_test, DICT_LENGTH)\n",
    "print(f'Length of vocabulary is {len(vocab)}')\n",
    "\n",
    "x_train_pad = padding_(x_train,MAX_STR_LENGTH)\n",
    "x_test_pad = padding_(x_test,MAX_STR_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     2,  3796,   375, 20562,  5503])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDataset, DataLoader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# create Tensor datasets\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m train_data \u001b[38;5;241m=\u001b[39m TensorDataset(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_pad\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_train))\n\u001b[0;32m      5\u001b[0m test_data \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_test_pad), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_test))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# dataloaders\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 128\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([60])\n",
      "Sample input: \n",
      " tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,   155,\n",
      "          163,   341,   400,    16,    62,   331,  1442,   155,  8986,   838,\n",
      "         2282,   402,   209,  3267, 28861,    84,  2210,    24,   163,   402,\n",
      "          152,  3690,   400,   460,   111,  4886,    33, 16557,    63,   400],\n",
      "       dtype=torch.int32)\n",
      "Sample input: \n",
      " tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter._dataset[0]\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    # Takes in 2 tensors\n",
    "\n",
    "    preds, labels = preds.cpu().detach().numpy(), labels.cpu().detach().numpy()\n",
    "    return f1_score(labels, preds, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_loader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    size = len(train_loader.dataset)\n",
    "    num_batches = len(train_loader)\n",
    "\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for word_embed, labels in train_loader:\n",
    "        # Transfering images and labels to GPU if available\n",
    "        word_embed, labels = word_embed.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass \n",
    "        outputs = model(word_embed)\n",
    "        outputs = outputs.type(torch.float64)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        \n",
    "        train_correct += (predicted == labels).type(torch.float).sum().item()\n",
    "\n",
    "    train_f1 = f1_score_func(predicted, labels)\n",
    "    train_loss /= num_batches\n",
    "    train_correct /=size\n",
    "    \n",
    "    return train_loss, train_correct, train_f1\n",
    "\n",
    "def test_loop(test_loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "\n",
    "    size = len(test_loader.dataset)\n",
    "    num_batches = len(test_loader)\n",
    "    test_loss, test_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for word_embed, labels in test_loader:\n",
    "\n",
    "            word_embed, labels = word_embed.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(word_embed)\n",
    "            outputs = outputs.type(torch.float64)\n",
    "\n",
    "            test_loss += loss_fn(outputs, labels).item()\n",
    "\n",
    "            predicted = torch.round(outputs)\n",
    "            test_correct += (predicted == labels).type(torch.float).sum().item()\n",
    "\n",
    "    test_f1 = f1_score_func(predicted, labels)\n",
    "    test_loss /= num_batches\n",
    "    test_correct /= size\n",
    "    \n",
    "    return test_loss, test_correct, test_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(69741, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc_extra): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from utils.models import SentimentRNN\n",
    "from utils.early_stopper import EarlyStopper\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
    "embedding_dim = 64\n",
    "hidden_dim = 256\n",
    "patience = 5\n",
    "\n",
    "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim)\n",
    "early_stopper = EarlyStopper(patience=patience, min_delta=0)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc epoch 0 : Acc 0.829953287000114 , F1 0.8594923594923595 \n",
      "Test Acc epoch 0 : Acc 0.8904078377762589 , F1 0.878489448352462 \n",
      "Train Acc epoch 1 : Acc 0.8904238350233565 , F1 0.9722007722007722 \n",
      "Test Acc epoch 1 : Acc 0.9035087719298246 , F1 0.9325195842608778 \n",
      "Train Acc epoch 2 : Acc 0.921385439216133 , F1 0.9444444444444444 \n",
      "Test Acc epoch 2 : Acc 0.9155844155844156 , F1 0.9451905321470538 \n",
      "Train Acc epoch 3 : Acc 0.9348866355246668 , F1 0.8888888888888888 \n",
      "Test Acc epoch 3 : Acc 0.918546365914787 , F1 0.9460249723407618 \n",
      "Train Acc epoch 4 : Acc 0.9481029964680415 , F1 0.9722869722869724 \n",
      "Test Acc epoch 4 : Acc 0.9260651629072681 , F1 0.9729333729333728 \n",
      "Train Acc epoch 5 : Acc 0.959240059245756 , F1 0.9168609168609169 \n",
      "Test Acc epoch 5 : Acc 0.9264069264069265 , F1 0.919037719037719 \n",
      "Train Acc epoch 6 : Acc 0.9563347385211348 , F1 0.9722869722869724 \n",
      "Test Acc epoch 6 : Acc 0.922077922077922 , F1 0.8918918918918919 \n",
      "Train Acc epoch 7 : Acc 0.9650791842315142 , F1 0.9442724458204333 \n",
      "Test Acc epoch 7 : Acc 0.919457735247209 , F1 0.918679211362138 \n",
      "Train Acc epoch 8 : Acc 0.977184687250769 , F1 0.9722007722007722 \n",
      "Test Acc epoch 8 : Acc 0.923900660742766 , F1 0.9457074721780604 \n",
      "Train Acc epoch 9 : Acc 0.9833371311382021 , F1 0.9722869722869724 \n",
      "Test Acc epoch 9 : Acc 0.9123946229209388 , F1 0.9594966457927383 \n",
      "Done! Early stopped at 10\n"
     ]
    }
   ],
   "source": [
    "#from Utils.common_functions import train_loop, test_loop\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 50\n",
    "# train for some number of epochs\n",
    "tr_acc, te_acc = [], []\n",
    "tr_loss, te_loss = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_correct, train_f1 = train_loop(train_loader, model, loss_fn, optimizer, device)\n",
    "    test_loss, test_correct, test_f1 = test_loop(test_loader, model, loss_fn, device)\n",
    "\n",
    "    print('Train Acc epoch {} : Acc {} , F1 {} '.format(epoch, train_correct, train_f1))\n",
    "    print('Test Acc epoch {} : Acc {} , F1 {} '.format(epoch, test_correct, test_f1))\n",
    "\n",
    "    tr_acc.append(train_correct)\n",
    "    te_acc.append(test_correct)\n",
    "\n",
    "    tr_loss.append(train_loss)\n",
    "    te_loss.append(test_loss)\n",
    "\n",
    "    if early_stopper.early_stop(test_loss):\n",
    "        print(\"Done! Early stopped at {}\".format(epoch+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985145926475525\n",
      "0.00047090023872442544\n",
      "0.960693895816803\n",
      "0.0005473597557283938\n",
      "0.9996005892753601\n"
     ]
    }
   ],
   "source": [
    "A = 'All I feel is anxiety'\n",
    "B = 'naruto is a great anime'\n",
    "C = 'I dont feel anything anymore'\n",
    "D = 'Lets have a picnic today!'\n",
    "E = 'I am wondering why there is so much talk about depression these days'\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def predict_text(text):\n",
    "    word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \n",
    "                        if preprocess_string(word) in vocab.keys()])\n",
    "    word_seq = np.expand_dims(word_seq,axis=0)\n",
    "    pad =  torch.from_numpy(padding_(word_seq,MAX_STR_LENGTH))\n",
    "    inputs = pad.to(device)\n",
    "    output = model(inputs)\n",
    "    return(output.item())\n",
    "\n",
    "print(predict_text(A))\n",
    "print(predict_text(B))\n",
    "print(predict_text(C))\n",
    "print(predict_text(D))\n",
    "print(predict_text(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
